# End-to-End
* [Survey: End-to-end Autonomous Driving: Challenges and Frontiers](https://arxiv.org/pdf/2306.16927.pdf)[[阅读笔记]](https://zhuanlan.zhihu.com/p/645591804/edit)
* [Survey: Recent Advancements in End-to-End Autonomous Driving using Deep Learning: A Survey](https://arxiv.org/pdf/2307.04370.pdf)
* [Github: End-to-end Autonomous Driving](https://github.com/OpenDriveLab/End-to-end-Autonomous-Driving)
* [POLICY PRE-TRAINING FOR AUTONOMOUS DRIVING VIA SELF-SUPERVISED GEOMETRIC MODELING](https://arxiv.org/pdf/2301.01006.pdf)
* [World Models](https://arxiv.org/abs/1803.10122)
* [SafetyNet: Safe planning for real-world self-driving vehicles using machine-learned policies](https://arxiv.org/pdf/2109.13602.pdf)
* [UniAD: Goal-oriented Autonomous Driving](https://github.com/OpenDriveLab/UniAD)
* [DriveAdapter: Breaking the Coupling Barrier of Perception and Planning in End-to-End Autonomous Driving](https://arxiv.org/pdf/2308.00398.pdf)
* [FusionAD: Multi-modality Fusion for Prediction and Planning Tasks of Autonomous Driving](https://arxiv.org/pdf/2308.01006.pdf) [[Code]](https://github.com/westlake-autolab/FusionAD)
* [Interpretable End-to-End Driving Model for Implicit Scene Understanding](https://arxiv.org/pdf/2308.01180.pdf)
* [GPT-DRIVER: LEARNING TO DRIVE WITH GPT](https://arxiv.org/pdf/2310.01415.pdf) [[阅读笔记]](https://zhuanlan.zhihu.com/p/660803092)
* [Perceive, Interact, Predict: Learning Dynamic and Static Clues for End-to-End Motion Prediction](https://arxiv.org/pdf/2212.02181.pdf)
* [VAD Vectorized Scene Representation for Efficient Autonomous Driving](https://arxiv.org/pdf/2303.12077.pdf)
* [ViP3D: End-to-end Visual Trajectory Prediction via 3D Agent Queries](https://arxiv.org/pdf/2208.01582.pdf)
* [MMFN: Multi-Modal-Fusion-Net for End-to-End Driving](https://arxiv.org/pdf/2207.00186.pdf)
* [Exploring Navigation Maps for Learning-Based Motion Prediction](https://arxiv.org/pdf/2302.06195.pdf)
* [ST-P3 End-to-end Vision-based Autonomous Driving via Spatial-Temporal Feature Learning](https://arxiv.org/pdf/2207.07601.pdf)
* [MP3: A Unified Model to Map, Perceive, Predict and Plan](https://arxiv.org/pdf/2101.06806.pdf)
* [Is Ego Status All You Need for Open-Loop End-to-End Autonomous Driving?](https://arxiv.org/pdf/2312.03031.pdf)


# LLM and AD
* [A Survey of Large Language Models for Autonomous Driving](https://arxiv.org/pdf/2311.01043.pdf) 
* [A Survey on Multimodal Large Language Models for Autonomous Driving](https://arxiv.org/pdf/2311.12320.pdf)
* [https://github.com/Thinklab-SJTU/Awesome-LLM4AD](https://github.com/Thinklab-SJTU/Awesome-LLM4AD)
* [DriveGPT4: Interpretable End-to-end Autonomous Driving via Large Language Model](https://arxiv.org/pdf/2310.01412.pdf)
* [ADAPT: Action-aware Driving Caption Transformer](https://arxiv.org/pdf/2302.00673.pdf)
* [Driving with LLMs Fusing Object-Level Vector Modality for Explainable Autonomous Driving](https://arxiv.org/pdf/2310.01957v1.pdf)
* [Language Prompt for Autonomous Driving](https://arxiv.org/pdf/2309.04379.pdf)
* [On the Road with GPT-4V(ision): Early Explorations of Visual-Language Model on Autonomous Driving](https://arxiv.org/pdf/2311.05332.pdf)
* [Vision Language Models in Autonomous Driving and Intelligent Transportation Systems](https://arxiv.org/pdf/2310.14414.pdf)
* [Bird’s-Eye-View Scene Graph for Vision-Language Navigation](https://arxiv.org/pdf/2308.04758.pdf) [【阅读笔记】](?)
* [Waymax: An Accelerated, Data-Driven Simulator for Large-Scale Autonomous Driving Research](https://arxiv.org/pdf/2310.08710v1.pdf)
* [BEVGPT: Generative Pre-trained Large Model for Autonomous Driving Prediction, Decision-Making, and Planning](https://arxiv.org/pdf/2310.10357.pdf)
* [UniPAD: A Universal Pre-training Paradigm for Autonomous Driving](https://arxiv.org/pdf/2310.08370.pdf)
* [A Practical Large-Scale Roadside Multi-View Multi-Sensor Spatial Synchronization Framework for Intelligent Transportation Systems](https://arxiv.org/pdf/2311.04231.pdf)
* [A Language Agent for Autonomous Driving](https://arxiv.org/pdf/2311.10813.pdf)
* [ADriver-I: A General World Model for Autonomous Driving](https://arxiv.org/pdf/2311.13549.pdf)
* [Panacea: Panoramic and Controllable Video Generation for Autonomous Driving](https://arxiv.org/pdf/2311.16813.pdf)
* [Reason2Drive: Towards Interpretable and Chain-based Reasoning for Autonomous Driving](https://arxiv.org/pdf/2312.03661.pdf)
* [Towards Knowledge-driven Autonomous Driving](https://arxiv.org/pdf/2312.04316.pdf)



