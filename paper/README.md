# BEV检测
* [Fast-BEV: A Fast and Strong Bird's-Eye View Perception Baseline](https://arxiv.org/abs/2301.12511) [[Code]](https://github.com/Sense-GVT/Fast-BEV) [[资料]](https://mp.weixin.qq.com/s/Dv8UVrRN2TrOTQCqVtDSJg)
* [MatrixVT: Efficient Multi-Camera to BEV Transformation for 3D Perception](https://arxiv.org/abs/2211.10593)
* [BEV-IO: Enhancing Bird’s-Eye-View 3D Detection with Instance Occupancy](https://arxiv.org/pdf/2305.16829.pdf)

# BEV分割
* [Learning and Aggregating Lane Graphs for Urban Automated Driving](https://arxiv.org/abs/2302.06175) 
* [InstaGraM Instance-level Graph Modeling for Vectorized HD Map Learning](https://arxiv.org/abs/2301.04470)

# LaneGraph
* [(2021) Structured Bird’s-Eye-View Traffic Scene Understanding from Onboard Images](https://arxiv.org/pdf/2110.01997.pdf)
* [(2022) Topology Preserving Local Road Network Estimation from Single Onboard Camera Image](https://openaccess.thecvf.com/content/CVPR2022/papers/Can_Topology_Preserving_Local_Road_Network_Estimation_From_Single_Onboard_Camera_CVPR_2022_paper.pdf)
* [(2022) Lane-Level Street Map Extraction from Aerial Imagery](https://openaccess.thecvf.com/content/WACV2022/papers/He_Lane-Level_Street_Map_Extraction_From_Aerial_Imagery_WACV_2022_paper.pdf)
* [(2023) Lane Graph as Path: Continuity-preserving Path-wise Modeling for Online Lane Graph Construction](https://github.com/hustvl/LaneGAP)
* HDmapNet VectorNetMap MapTR

# Occupancy
* [Tri-Perspective View for Vision-Based 3D Semantic Occupancy Prediction](https://arxiv.org/pdf/2302.07817.pdf) [[Code]](https://github.com/wzzheng/TPVFormer)
* [MonoScene Monocular 3D Semantic Scene Completion](https://arxiv.org/abs/2112.00726)
* [OccDepth: A Depth-aware Method for 3D Semantic Occupancy Network](https://arxiv.org/abs/2302.13540)
* [VoxFormer: Sparse Voxel Transformer for Camera-based 3D Semantic Scene Completion](https://arxiv.org/abs/2302.12251)
* [OpenOccupancy: A Large Scale Benchmark for Surrounding Semantic Occupancy Perception](https://github.com/JeffWang987/OpenOccupancy)
* [A Simple Attempt for 3D Occupancy Estimation in Autonomous Driving](https://github.com/GANWANSHUI/SimpleOccupancy)
* [Occ-BEV: Multi-Camera Unified Pre-training via 3D Scene Reconstruction](https://arxiv.org/pdf/2305.18829.pdf)
* [Learning Occupancy for Monocular 3D Object Detection](https://arxiv.org/pdf/2305.15694.pdf)
* [Scene as Occupancy](https://arxiv.org/pdf/2306.02851.pdf) [[Code]](https://github.com/OpenDriveLab/OccNet)


# 矢量化
* [PolyFormer Referring Image Segmentation as Sequential Polygon Generation](https://arxiv.org/abs/2302.07387)


# 多传感器融合
* [Transformers-Sensor-Fusion](https://github.com/ApoorvRoboticist/Transformers-Sensor-Fusion)


# 检测跟踪一体化
* [Exploring Simple 3D Multi-Object Tracking for Autonomous Driving](https://github.com/qcraftai/simtrack)
* [MOTR: End-to-End Multiple-Object Tracking with TRansformer](https://github.com/megvii-research/MOTR)
* [MUTR3D: A Multi-camera Tracking Framework via 3D-to-2D Queries](https://tsinghua-mars-lab.github.io/mutr3d/)


# End-to-End
* [POLICY PRE-TRAINING FOR AUTONOMOUS DRIVING VIA SELF-SUPERVISED GEOMETRIC MODELING](https://arxiv.org/pdf/2301.01006.pdf)
* [World Models](https://arxiv.org/abs/1803.10122)
* [SafetyNet: Safe planning for real-world self-driving vehicles using machine-learned policies](https://arxiv.org/pdf/2109.13602.pdf)
* [Goal-oriented Autonomous Driving](https://github.com/OpenDriveLab/UniAD)

# Prediction
* [Motion Transformer with Global Intention Localization and Local Movement Refinement](https://arxiv.org/pdf/2209.13508.pdf)


# Calibration
* [☆] [Calib-Anything: Zero-training LiDAR-Camera Extrinsic Calibration
Method Using Segment Anything](https://arxiv.org/pdf/2306.02656.pdf)